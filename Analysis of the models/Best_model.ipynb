{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our best model\n",
    "In this document we will analyze our best model in order to see why it has worked the best among the others, which aspects we neede to take into consideration and the efficiency of the model based on the time of execution needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Choosing [FlauBERT (accuracy of 56.5%) :](https://github.com/Oglo/Project-DSML/blob/main/Code/Methods/10_FlauBert.ipynb) for French Language Proficiency Classification**\n",
    "\n",
    "Our project employs FlauBERT, a model specifically designed for the French language, to classify texts into distinct language proficiency levels. This selection is particularly well-suited given FlauBERT's fine-tuned understanding of the French language, making it highly effective in distinguishing between different levels of language complexity.\n",
    "\n",
    "\n",
    "<u>**Data Preparation and Transformation**</u>\n",
    "\n",
    "In the initial stages, we've mapped the language proficiency levels (A1, A2, B1, B2, C1, C2) to numeric labels, a crucial step for the model's understanding as it processes numerical values more effectively than categorical data. The TextDataset class plays a significant role here, utilizing FlauBERT's tokenizer to transform texts into a format that's comprehensible for the model. This transformation is key to breaking down the language in a way that highlights its unique structure and nuances.\n",
    "\n",
    "Data splitting follows, an essential yet standard process, dividing our dataset into training and validation sets. This allows our model to learn from one subset of data and then validate its learning on another, ensuring that the model is effective and adaptable.\n",
    "\n",
    "\n",
    "<u>**Model Training and Optimization**</u>\n",
    "\n",
    "Central to our project is the training process, where we initialize FlauBERT to recognize six language levels. We employ the AdamW optimizer and a learning rate scheduler, ensuring effective and adaptable learning. Each training epoch is closely monitored for the model’s performance on the validation set, ensuring accurate learning and avoiding overfitting.\n",
    "\n",
    "\n",
    "<u>**Evaluation and Prediction**</u>\n",
    "\n",
    "In the prediction phase, our model's efficacy is tested on new data. The predictions are then mapped back to our language proficiency labels, providing a clear measure of the model’s capability to generalize its learned patterns to unseen texts.\n",
    "\n",
    "\n",
    "<u>**Data Augmentation for Enhanced Accuracy**</u>\n",
    "\n",
    "A pivotal decision in our methodology was to double the data volume for this trial. This augmentation significantly contributed to the model's improved accuracy, as a larger dataset provides more varied learning examples, leading to a better understanding of language patterns and higher classification precision.\n",
    "\n",
    "In summary, the strategic combination of using FlauBERT and increasing the dataset size has been instrumental in our project's success. Achieving a precision of 56.5%, our model demonstrates an effective understanding of the complexities in French language proficiency levels. The synergy between a tailored language model and an extensive dataset highlights the strength of our approach in accurately classifying French text."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
